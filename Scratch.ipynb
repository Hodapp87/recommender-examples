{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems (Movie Reviews)\n",
    "- Done as part of a SharpestMinds skills test\n",
    "- Author: Chris Hodapp\n",
    "- Date: 2018-02-04\n",
    "\n",
    "This assumes that `ml-100k` from movielens data (should be the `ml-100k` archive from https://grouplens.org/datasets/movielens/100k/) has been downloaded and uncompressed in the local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = pd.read_csv(\"ml-100k/u.data\", sep=\"\\t\", header=None,\n",
    "                 names=(\"user_id\", \"movie_id\", \"rating\", \"time\"))\n",
    "# Convert Unix seconds to a Pandas timestamp:\n",
    "ml[\"time\"] = pd.to_datetime(ml[\"time\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-12-04 15:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-04-04 19:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1997-11-07 07:18:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-11-27 05:02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-02-02 05:33:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-01-07 14:20:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-12-03 17:51:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>1998-04-03 18:34:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-02-01 09:20:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-12-31 21:16:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating                time\n",
       "0      196       242       3 1997-12-04 15:55:49\n",
       "1      186       302       3 1998-04-04 19:22:22\n",
       "2       22       377       1 1997-11-07 07:18:36\n",
       "3      244        51       2 1997-11-27 05:02:03\n",
       "4      166       346       1 1998-02-02 05:33:16\n",
       "5      298       474       4 1998-01-07 14:20:06\n",
       "6      115       265       2 1997-12-03 17:51:28\n",
       "7      253       465       5 1998-04-03 18:34:27\n",
       "8      305       451       3 1998-02-01 09:20:17\n",
       "9        6        86       3 1997-12-31 21:16:53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1683, 1588752)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_user  = int(ml[\"user_id\"].max() + 1)\n",
    "max_movie = int(ml[\"movie_id\"].max() + 1)\n",
    "max_user, max_movie, max_user * max_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of data sparsity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06294248567429025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.shape[0] / (max_user * max_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/testing split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train, ml_test = sklearn.model_selection.train_test_split(ml, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to utility matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a mask for some later steps, hence the m > 0 step; ratings go only from 1 to 5, so values of 0 are automatically unknown/missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2mat(df):\n",
    "    m = np.zeros((max_user, max_movie))\n",
    "    m[df[\"user_id\"], df[\"movie_id\"]] = df[\"rating\"]\n",
    "    return m, m > 0\n",
    "ml_mat_train, ml_mask_train = df2mat(ml_train)\n",
    "ml_mat_test,  ml_mask_test  = df2mat(ml_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this were an actual large amount of data, which a 944x1683 matrix doesn't really count as, you'd probably want [sparse matrices](https://docs.scipy.org/doc/scipy/reference/sparse.html) and to use 8-bit ints rather than 32-bit floats, for instance:\n",
    "\n",
    "```python\n",
    "ml_mat = scipy.sparse.coo_matrix(\n",
    "    (ml[\"rating\"], (ml[\"user_id\"], ml[\"movie_id\"])),\n",
    "    shape=(max_user, max_movie),\n",
    "    dtype=np.int8)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope One implementation\n",
    "\n",
    "- Based on:  [Slope One Predictors for Online Rating-Based Collaborative Filtering](https://arxiv.org/pdf/cs/0702144v1.pdf)\n",
    "- TODO: This needs better explanation but I'm not sure if it should reside here, in the Python code, or in the blag post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deviation(M, mask):\n",
    "    m,n = M.shape\n",
    "    m2 = mask.astype(np.int)\n",
    "    counts = m2.T @ m2\n",
    "    S = m2.T @ M\n",
    "    diffs = S.T - S\n",
    "    dev = diffs / np.maximum(1, counts)\n",
    "    return dev, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of 'deviation' above might be less-optimal vastly larger matrices. For one thing, Slope One doesn't really *need* a utility matrix, though it's easier from one. One could readily compute deviation from the list of ratings, though I don't know a fast way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_one(M, mask, dev, counts, u, j, weighted = False):\n",
    "    m,n = M.shape\n",
    "    # S_u is a mask over M's columns for items user 'u' rated:\n",
    "    S_u = mask[u, :]\n",
    "    if weighted:\n",
    "        # In 'Weighted Slope One', we sum over everything user 'u' rated,\n",
    "        # regardless of whether other users rated both this and item j:\n",
    "        S_u[j] = False\n",
    "        c_j = counts[j, S_u]\n",
    "        devs = dev[j, S_u]\n",
    "        u = M[u, S_u]\n",
    "        return ((devs + u) * c_j).sum() / max(1.0, c_j.sum())\n",
    "    else:\n",
    "        # In the 'Slope One' formula we are summing over R_j, which is:\n",
    "        # Every item 'i' (i != j), such that: user 'u' rated item 'i', and\n",
    "        # at least one other user rated both item 'i' and item 'j'.\n",
    "        # Below we compute this likewise as a mask over M's columns:\n",
    "        R_j = S_u * (counts[u, :] > 0)\n",
    "        R_j[j] = False\n",
    "        u = M[u, R_j].sum()\n",
    "        devs = dev[j, R_j].sum()\n",
    "        card = max(1.0, R_j.sum())\n",
    "        return (u + devs) / card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(M, mask, dev, counts, dataframe, weighted=False):\n",
    "    err_mae = 0\n",
    "    err_rms = 0\n",
    "    for row in dataframe.itertuples():\n",
    "        p = predict_one(M, mask, dev, counts,\n",
    "                        row.user_id, row.movie_id, weighted=weighted)\n",
    "        err_mae += np.abs(p - row.rating)\n",
    "        err_rms += np.square(p - row.rating)\n",
    "    err_mae = err_mae / len(dataframe)\n",
    "    err_rms = np.sqrt(err_rms / len(dataframe))\n",
    "    return err_mae, err_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute deviation (which is basically our model) from training:\n",
    "dev, counts = deviation(ml_mat_train, ml_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_mae_train, err_rms_train = predict(ml_mat_train, ml_mask_train, dev, counts, ml_train)\n",
    "err_mae_test,  err_rms_test  = predict(ml_mat_test,  ml_mask_test,  dev, counts, ml_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: MAE=0.6705920085426367, RMS=0.8698715649103287\n",
      "Testing error: MAE=0.7690465575577171, RMS=0.9922856864635986\n"
     ]
    }
   ],
   "source": [
    "print(\"Training error: MAE={}, RMS={}\".format(err_mae_train, err_rms_train))\n",
    "print(\"Testing error: MAE={}, RMS={}\".format(err_mae_test, err_rms_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_mae_train, err_rms_train = predict(ml_mat_train, ml_mask_train, dev, counts, ml_train, True)\n",
    "err_mae_test,  err_rms_test  = predict(ml_mat_test,  ml_mask_test,  dev, counts, ml_test,  True)\n",
    "# why must I pass both dataframe and matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: MAE=0.7366789114708739, RMS=0.9834047856298306\n",
      "Testing error: MAE=0.8970442751834006, RMS=1.2349462361157233\n"
     ]
    }
   ],
   "source": [
    "print(\"Training error: MAE={}, RMS={}\".format(err_mae_train, err_rms_train))\n",
    "print(\"Testing error: MAE={}, RMS={}\".format(err_mae_test, err_rms_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementations in `scikit-surprise`\n",
    "\n",
    "[Surprise](http://surpriselib.com/) contains implementations of many of the same things, so these are tested below. This same dataset is included as a built-in, but for consistency, we may as well load it from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = surprise.Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ml[[\"user_id\", \"movie_id\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.09823107719421387,\n",
       "  0.09905147552490234,\n",
       "  0.09962821006774902,\n",
       "  0.09817862510681152,\n",
       "  0.09549379348754883),\n",
       " 'test_mae': array([ 1.22155201,  1.22409488,  1.22286712,  1.21837144,  1.22539256]),\n",
       " 'test_rmse': array([ 1.5236036 ,  1.52539035,  1.52403493,  1.51874752,  1.52268848]),\n",
       " 'test_time': (0.22506093978881836,\n",
       "  0.22594857215881348,\n",
       "  0.2251570224761963,\n",
       "  0.22582459449768066,\n",
       "  0.2660207748413086)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.model_selection.cross_validate(surprise.NormalPredictor(), data, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.7243213653564453,\n",
       "  0.7411255836486816,\n",
       "  0.812612771987915,\n",
       "  0.8363091945648193,\n",
       "  0.669187068939209),\n",
       " 'test_mae': array([ 0.746087  ,  0.74980919,  0.73966436,  0.74414759,  0.73613966]),\n",
       " 'test_rmse': array([ 0.94990862,  0.95352051,  0.94189575,  0.94693599,  0.93514955]),\n",
       " 'test_time': (2.5336906909942627,\n",
       "  2.3776566982269287,\n",
       "  2.3864481449127197,\n",
       "  2.502324342727661,\n",
       "  2.2572689056396484)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.model_selection.cross_validate(surprise.SlopeOne(), data, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (5.609443664550781,\n",
       "  5.635587453842163,\n",
       "  5.525452136993408,\n",
       "  5.772013902664185,\n",
       "  4.828369617462158),\n",
       " 'test_mae': array([ 0.744339  ,  0.74548684,  0.72696361,  0.73389245,  0.73644925]),\n",
       " 'test_rmse': array([ 0.94308608,  0.94312428,  0.92535598,  0.93239132,  0.93154266]),\n",
       " 'test_time': (0.24836158752441406,\n",
       "  0.2776060104370117,\n",
       "  0.24745988845825195,\n",
       "  0.2395009994506836,\n",
       "  0.28363823890686035)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.model_selection.cross_validate(surprise.SVD(), data, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
